import pandas as pd
import os
import numpy as np

# Configurar caminhos
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
DATA_DIR = os.path.join(PROJECT_ROOT, 'data')
RAW_DIR = os.path.join(DATA_DIR, 'raw')
PROCESSED_DIR = os.path.join(DATA_DIR, 'processed')

# Criar diretÃ³rios se nÃ£o existirem
os.makedirs(PROCESSED_DIR, exist_ok=True)

print("ğŸš€ Iniciando preparaÃ§Ã£o dos dados...")
print(f"ğŸ“‚ Lendo arquivos de: {RAW_DIR}")
print(f"ğŸ’¾ Salvando resultados em: {PROCESSED_DIR}")

# %%
# Ler os 3 arquivos CSV
try:
    df_location = pd.read_csv(os.path.join(RAW_DIR, "meta_analysis_location.csv"))
    df_meta = pd.read_csv(os.path.join(RAW_DIR, "meta_analysis_performance_value_meta.csv"))
    df_prices = pd.read_csv(os.path.join(RAW_DIR, "meta_analysis_price.csv"))
    print("âœ… Todos os arquivos CSV lidos com sucesso")
except FileNotFoundError as e:
    print(f"âŒ Erro ao ler arquivos: {e}")
    print("Execute primeiro o script 1_import_data.py")
    exit(1)

# %%
# Renomear colunas do df_meta conforme o padrÃ£o
df_meta = df_meta.rename(columns={
    "group_name": "categoria",
    "num_listing_blocked": "dias_bloqueados",
    "n_days_status": "dias_ativo",
    "listing_fat": "faturamento_mes",
    "n_competitors": "n_concorrentes",
    "meta_value": "meta",
    "year_month": "mes_ano",
    "to_competitors": "to_concorrentes",
    "days_occupied": "dias_ocupados",
    "total_days": "total_dias"
})

print("ğŸ“ Colunas renomeadas no df_meta")

# %%
# Verificar nomes das colunas
print("\nğŸ“Œ Colunas de df_location:")
print(df_location.columns.tolist())

print("\nğŸ“Œ Colunas de df_meta:")
print(df_meta.columns.tolist())

print("\nğŸ“Œ Colunas de df_prices:")
print(df_prices.columns.tolist())

# %%
# Fazer merge entre os DataFrames
print("\nğŸ”— Realizando merges dos DataFrames...")
# Primeiro, juntar df_meta com df_prices
df_merged = df_meta.merge(df_prices, on="listing", how="left")

# Depois, juntar com df_location
df_final = df_merged.merge(df_location, on="listing", how="left")
print(df_final.columns)
print(f"âœ… Merge concluÃ­do")
print(f" - df_meta: {len(df_meta)} linhas")
print(f" - df_final: {len(df_final)} linhas")

# %%
# Reordenar colunas
colunas_ordenadas = [
    "listing",
    "categoria",
    "carteira",
    "estado",
    "cidade",
    "Bairro",
    "dias_bloqueados",
    "dias_ativo",
    "faturamento_mes",
    "n_concorrentes",
    "meta",
    "mes_ano",
    "to_listings",
    "to_concorrentes",
    "dias_ocupados",
    "total_dias",
    "media_preco_ocupado",
    "media_preco_disponivel",
    "ocupacao_ainda_disponivel",
    "data_da_execucao"
]

# Manter apenas colunas que existem no df_final
colunas_ordenadas = [col for col in colunas_ordenadas if col in df_final.columns]
df_final = df_final[colunas_ordenadas]
print(df_final.columns)
print("ğŸ“‹ Colunas reordenadas")

# %%
# Calcular atingimento da meta (evitar divisÃ£o por zero)
print("\nğŸ“Š Calculando mÃ©tricas derivadas...")
df_final["atingimento_meta"] = df_final.apply(
    lambda row: row["faturamento_mes"] / row["meta"] if row["meta"] > 0 else 0,
    axis=1
)

# Classificar grupo de criticidade
def classificar_criticidade(atingimento):
    if atingimento <= 0.5:
        return "crÃ­tico"
    elif atingimento <= 0.8:
        return "atenÃ§Ã£o"
    elif atingimento <= 1.1:
        return "berlinda"
    elif atingimento <= 2.0:
        return "ok"
    else:
        return "meta_subestimada"

df_final["grupo_criticidade"] = df_final["atingimento_meta"].apply(classificar_criticidade)

# Arredondar atingimento para 2 casas
df_final["atingimento_meta"] = df_final["atingimento_meta"].round(2)

print("âœ… MÃ©tricas derivadas calculadas")

# %%
# Calcular mÃ©tricas para a Berlinda
print("\nğŸ¯ Calculando mÃ©tricas especÃ­ficas para Berlinda...")

# Filtrar apenas Berlinda
df_berlinda = df_final[df_final["grupo_criticidade"] == "berlinda"].copy()

if len(df_berlinda) > 0:
    # <<< CORREÃ‡ÃƒO 1: Extrair a data de referÃªncia do DataFrame
    # Isso garante que o cÃ¡lculo dos dias disponÃ­veis seja preciso
    data_execucao_berlinda = pd.to_datetime(df_berlinda['data_da_execucao'].iloc[0])
    ULTIMO_DIA_MES = data_execucao_berlinda + pd.offsets.MonthEnd(0)
    
    # <<< CORREÃ‡ÃƒO 2: Calcular 'dias_disponiveis' com base na data de execuÃ§Ã£o
    if data_execucao_berlinda.date() == ULTIMO_DIA_MES.date():
        df_berlinda['dias_disponiveis'] = 0
    else:
        dias_restantes = (ULTIMO_DIA_MES - data_execucao_berlinda).days
        df_berlinda['dias_disponiveis'] = df_berlinda['ocupacao_ainda_disponivel'].clip(upper=dias_restantes).fillna(0).astype(int)

    # Calcular mÃ©tricas adicionais
    df_berlinda["falta_meta"] = df_berlinda["meta"] - df_berlinda["faturamento_mes"]
    
    # Calcular dias necessÃ¡rios (evitar divisÃ£o por zero)
    df_berlinda["dias_necessarios"] = df_berlinda.apply(
        lambda row: np.ceil(row["falta_meta"] / row["media_preco_disponivel"]) 
        if row["media_preco_disponivel"] > 0 else 0,
        axis=1
    )
    
    # Calcular potencial mÃ¡ximo
    df_berlinda["potencial_max"] = (
        df_berlinda["faturamento_mes"] + 
        (df_berlinda["dias_disponiveis"] * df_berlinda["media_preco_disponivel"]) # <<< Usar a nova coluna
    )
    
    # Calcular potencial realista
    df_berlinda["potencial_realista"] = (
        df_berlinda["faturamento_mes"] + 
        (df_berlinda["to_listings"] * df_berlinda["dias_disponiveis"] * df_berlinda["media_preco_disponivel"]) # <<< Usar a nova coluna
    )
    
    # Calcular score bruto
    df_berlinda["score_bruto"] = (
        (df_berlinda["falta_meta"] / df_berlinda["meta"]) *
        (1 / df_berlinda["dias_disponiveis"].replace(0, 1)) * # <<< Usar a nova coluna
        (df_berlinda["potencial_max"] - df_berlinda["faturamento_mes"]) *
        (1 / df_berlinda["dias_necessarios"].replace(0, 1))
    )
    
    # Normalizar score por rank percentil
    df_berlinda["score_normalizado"] = df_berlinda["score_bruto"].rank(pct=True) * 100
    
    # <<< CORREÃ‡ÃƒO 3: Atualizar a funÃ§Ã£o e o nome da coluna de prioridade
    def classificar_prioridade(score):
        if score >= 80:
            return "CrÃ­tico"
        elif score >= 50:
            return "Alta"
        elif score >= 20:
            return "MÃ©dia"
        else:
            return "Baixa"
    
    df_berlinda["faixa_prioridade"] = df_berlinda["score_normalizado"].apply(classificar_prioridade) # <<< Nome da coluna corrigido
    
    # Classificar status operacional
    def classificar_status(row):
        if row["atingimento_meta"] >= 1.0:
            if row["dias_disponiveis"] > 0: # <<< Usar a nova coluna
                if row["potencial_realista"] > row["meta"] * 1.1:
                    return "ğŸŸ¢ Acima com folga"
                else:
                    return "ğŸŸ¡ Acima com risco"
            else:
                return "ğŸŸ¡ Acima sem aÃ§Ã£o"
        else:
            if row["dias_disponiveis"] == 0: # <<< Usar a nova coluna
                return "ğŸ”´ Abaixo inviÃ¡vel"
            elif row["dias_necessarios"] <= row["dias_disponiveis"] and row["potencial_realista"] >= row["meta"]: # <<< Usar a nova coluna
                return "ğŸŸ¢ Abaixo viÃ¡vel"
            else:
                return "ğŸŸ  Abaixo precisa esforÃ§o"
    
    df_berlinda["status_operacional"] = df_berlinda.apply(classificar_status, axis=1)
    
    print(f"âœ… MÃ©tricas da Berlinda calculadas para {len(df_berlinda)} imÃ³veis")
else:
    print("âš ï¸ Nenhum imÃ³vel encontrado na Berlinda")
    df_berlinda = pd.DataFrame()  # DataFrame vazio

# %%
# Salvar resultados
print("\nğŸ’¾ Salvando arquivos processados...")

# ==============================================================================
# 1. NOVO: Extrair a data de execuÃ§Ã£o para o nome do arquivo
# ==============================================================================
# Verificamos se o DataFrame nÃ£o estÃ¡ vazio antes de tentar acessar a coluna
if not df_final.empty:
    # Pega a data da primeira linha, converte para o formato datetime e depois para string 'YYYY-MM-DD'
    run_date_str = pd.to_datetime(df_final['data_da_execucao'].iloc[0]).strftime('%Y-%m-%d')
else:
    # Fallback: caso o DataFrame esteja vazio, usa a data atual
    run_date_str = pd.to_datetime('today').strftime('%Y-%m-%d')
print("âš ï¸ DataFrame final vazio. Usando data atual para o nome do arquivo.")

# O nome do arquivo agora inclui a data da execuÃ§Ã£o
output_final = os.path.join(PROCESSED_DIR, f"meta_analysis_final_enriched_{run_date_str}.csv")
df_final.to_csv(output_final, index=False, encoding='utf-8')
print(f"âœ… Salvo: {output_final}")

# Salvar DataFrame da Berlinda
if len(df_berlinda) > 0:
    # O nome do arquivo tambÃ©m inclui a data da execuÃ§Ã£o
    output_berlinda = os.path.join(PROCESSED_DIR, f"berlinda_prepared_{run_date_str}.csv")
    df_berlinda.to_csv(output_berlinda, index=False, encoding='utf-8')
    print(f"âœ… Salvo: {output_berlinda}")

# %%
# %%
# Exibir estatÃ­sticas finais
print("\nğŸ“Š EstatÃ­sticas finais:")
print(f"ğŸ“ˆ Total de imÃ³veis analisados: {len(df_final)}")
print(f"ğŸ¯ ImÃ³veis na Berlinda: {len(df_berlinda)}")

if len(df_berlinda) > 0:
    print("\nğŸ“‹ DistribuiÃ§Ã£o de status na Berlinda:")
    print(df_berlinda["status_operacional"].value_counts())
    
    # <<< CORREÃ‡ÃƒO: Alterar o nome da coluna para 'faixa_prioridade'
    print("\nğŸ“‹ DistribuiÃ§Ã£o de prioridade na Berlinda:")
    print(df_berlinda["faixa_prioridade"].value_counts())

print("\nğŸ“‰ Valores nulos no DataFrame final:")
print(df_final.isnull().sum())

print("\nğŸ‰ Processamento concluÃ­do com sucesso!")
