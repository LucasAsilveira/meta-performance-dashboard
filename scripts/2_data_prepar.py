import pandas as pd
import os
import numpy as np

# Configurar caminhos
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
DATA_DIR = os.path.join(PROJECT_ROOT, 'data')
RAW_DIR = os.path.join(DATA_DIR, 'raw')
PROCESSED_DIR = os.path.join(DATA_DIR, 'processed')

# Criar diretÃ³rios se nÃ£o existirem
os.makedirs(PROCESSED_DIR, exist_ok=True)

print("ðŸš€ Iniciando preparaÃ§Ã£o dos dados...")
print(f"ðŸ“‚ Lendo arquivos de: {RAW_DIR}")
print(f"ðŸ’¾ Salvando resultados em: {PROCESSED_DIR}")

# %%
# %%
# %%
# Ler os 4 arquivos CSV (incluindo Pmin)
try:
    df_location = pd.read_csv(os.path.join(RAW_DIR, "meta_analysis_location.csv"))
    df_meta = pd.read_csv(os.path.join(RAW_DIR, "meta_analysis_performance_value_meta.csv"))
    df_prices = pd.read_csv(os.path.join(RAW_DIR, "meta_analysis_price.csv"))
    print("âœ… Arquivos CSV principais lidos com sucesso")

    # <<< NOVO: Tentar ler o arquivo de Pmin (nome fixo)
    try:
        df_pmin = pd.read_csv(os.path.join(RAW_DIR, 'meta_analysis_pmin.csv'))
        # <<< CORREÃ‡ÃƒO: Remover colunas desnecessÃ¡rias para nÃ£o quebrar o merge
        if 'data_da_execucao' in df_pmin.columns:
            df_pmin = df_pmin.drop(columns=['data_da_execucao'])
        print("âœ… Arquivo de Pmin lido e limpo com sucesso: meta_analysis_pmin.csv")
    except FileNotFoundError:
        df_pmin = pd.DataFrame()
        print("âš ï¸ Arquivo 'meta_analysis_pmin.csv' nÃ£o encontrado. A coluna 'dias_pmin' nÃ£o serÃ¡ criada.")
    except Exception as e:
        df_pmin = pd.DataFrame()
        print(f"âš ï¸ Erro inesperado ao ler Pmin: {e}. A coluna 'dias_pmin' nÃ£o serÃ¡ criada.")

except FileNotFoundError as e:
    print(f"âŒ Erro ao ler arquivos principais: {e}")
    print("Execute primeiro o script 1_import_data.py")
    exit(1)

# %%
# Renomear colunas do df_meta conforme o padrÃ£o
df_meta = df_meta.rename(columns={
    "group_name": "categoria",
    "num_listing_blocked": "dias_bloqueados",
    "n_days_status": "dias_ativo",
    "listing_fat": "faturamento_mes",
    "n_competitors": "n_concorrentes",
    "meta_value": "meta",
    "year_month": "mes_ano",
    "to_competitors": "to_concorrentes",
    "days_occupied": "dias_ocupados",
    "total_days": "total_dias"
})

print("ðŸ“ Colunas renomeadas no df_meta")

# %%
# Verificar nomes das colunas
print("\nðŸ“Œ Colunas de df_location:")
print(df_location.columns.tolist())

print("\nðŸ“Œ Colunas de df_meta:")
print(df_meta.columns.tolist())

print("\nðŸ“Œ Colunas de df_prices:")
print(df_prices.columns.tolist())

# %%
# %%
# Fazer merge entre os DataFrames
print("\nðŸ”— Realizando merges dos DataFrames...")
# Primeiro, juntar df_meta com df_prices
df_merged = df_meta.merge(df_prices, on="listing", how="left")

# Depois, juntar com df_location
df_merged = df_merged.merge(df_location, on="listing", how="left")

#Juntar com df_pmin, se existir
if not df_pmin.empty:
    df_final = df_merged.merge(df_pmin, on="listing", how="left")
    # Renomear a coluna para o padrÃ£o do nosso DataFrame
    df_final = df_final.rename(columns={'n_dates_special_price': 'dias_pmin'})
    print("âœ… Merge com Pmin concluÃ­do.")
else:
    df_final = df_merged
    print("âš ï¸ Merge com Pmin pulado (arquivo nÃ£o encontrado).")

#Limpar colunas de data duplicadas do merge
cols_to_drop = [col for col in df_final.columns if 'data_da_execucao' in col and col != 'data_da_execucao']
df_final = df_final.drop(columns=cols_to_drop)
if cols_to_drop:
    print(f"ðŸ§¹ Limpando colunas de data duplicadas: {cols_to_drop}")

print(df_final.columns)
print(f"âœ… Merge geral concluÃ­do")

print(df_final.columns)
print(f"âœ… Merge geral concluÃ­do")
print(f" - df_meta: {len(df_meta)} linhas")
print(f" - df_final: {len(df_final)} linhas")

# %%
# Reordenar colunas
colunas_ordenadas = [
    "listing",
    "categoria",
    "carteira",
    "estado",
    "cidade",
    "Bairro",
    "dias_bloqueados",
    "dias_ativo",
    "faturamento_mes",
    "n_concorrentes",
    "meta",
    "mes_ano",
    "to_listings",
    "to_concorrentes",
    "dias_ocupados",
    "total_dias",
    "media_preco_ocupado",
    "media_preco_disponivel",
    "ocupacao_ainda_disponivel",
    "dias_pmin",
    "data_da_execucao"
]

# Manter apenas colunas que existem no df_final
colunas_ordenadas = [col for col in colunas_ordenadas if col in df_final.columns]
df_final = df_final[colunas_ordenadas]
print(df_final.columns)
print("ðŸ“‹ Colunas reordenadas")

# %%
# Calcular atingimento da meta (evitar divisÃ£o por zero)
print("\nðŸ“Š Calculando mÃ©tricas derivadas...")
df_final["atingimento_meta"] = df_final.apply(
    lambda row: row["faturamento_mes"] / row["meta"] if row["meta"] > 0 else 0,
    axis=1
)

# %%
# Calcular mÃ©tricas de impacto financeiro
print("\nðŸ’° Calculando mÃ©tricas de impacto financeiro...")

# Garantir que as colunas sejam numÃ©ricas para o cÃ¡lculo, tratando erros
df_final['dias_bloqueados'] = pd.to_numeric(df_final['dias_bloqueados'], errors='coerce').fillna(0)
df_final['media_preco_ocupado'] = pd.to_numeric(df_final['media_preco_ocupado'], errors='coerce').fillna(0)
df_final['faturamento_mes'] = pd.to_numeric(df_final['faturamento_mes'], errors='coerce').fillna(0)
df_final['meta'] = pd.to_numeric(df_final['meta'], errors='coerce').fillna(0)

# Calcular Faturamento Perdido por Bloqueio
df_final['faturamento_perdido_bloqueio'] = df_final['dias_bloqueados'] * df_final['media_preco_ocupado']

# Calcular Falta para a Meta
df_final['falta_meta'] = df_final['meta'] - df_final['faturamento_mes']

print("âœ… MÃ©tricas de impacto financeiro calculadas")

# Classificar grupo de criticidade
def classificar_criticidade(atingimento):
    if atingimento <= 0.5:
        return "crÃ­tico"
    elif atingimento <= 0.8:
        return "atenÃ§Ã£o"
    elif atingimento <= 1.1:
        return "berlinda"
    elif atingimento <= 2.0:
        return "ok"
    else:
        return "meta_subestimada"

df_final["grupo_criticidade"] = df_final["atingimento_meta"].apply(classificar_criticidade)

# Arredondar atingimento para 2 casas
df_final["atingimento_meta"] = df_final["atingimento_meta"].round(2)

print("âœ… MÃ©tricas derivadas calculadas")

# ==============================================================================
# BLOCO DE DEPURAÃ‡ÃƒO (PARA REMOVER DEPOIS)
# ==============================================================================
DEBUG_MODE = True  # Mude para False para desativar os prints

if DEBUG_MODE:
    print("\n" + "="*50)
    print("ðŸ› INICIANDO MODO DEPURAÃ‡ÃƒO")
    print("="*50)

    # 1. Verificar as colunas base antes de qualquer cÃ¡lculo
    print("\nðŸ“Œ AnÃ¡lise da coluna 'meta' em df_meta:")
    print(df_meta['meta'].describe())
    print(f"Quantos 'meta' sÃ£o zero ou nulos? {(df_meta['meta'].isna() | (df_meta['meta'] == 0)).sum()}")

    print("\nðŸ“Œ AnÃ¡lise da coluna 'faturamento_mes' em df_meta:")
    print(df_meta['faturamento_mes'].describe())
    print(f"Quantos 'faturamento_mes' sÃ£o zero ou nulos? {(df_meta['faturamento_mes'].isna() | (df_meta['faturamento_mes'] == 0)).sum()}")

    # 2. Verificar o atingimento e a criticidade no DataFrame final
    print("\nðŸ“Œ AnÃ¡lise da coluna 'atingimento_meta' em df_final:")
    print(df_final['atingimento_meta'].describe())

    print("\nðŸ“Œ DISTRIBUIÃ‡ÃƒO FINAL - Contagem de grupo_criticidade em df_final:")
    contagem_criticidade = df_final['grupo_criticidade'].value_counts()
    print(contagem_criticidade)
    
    if 'berlinda' not in contagem_criticidade:
        print("\nðŸš¨ ATENÃ‡ÃƒO: Nenhum imÃ³vel foi classificado como 'berlinda'!")
    else:
        print(f"\nâœ… Encontrados {contagem_criticidade['berlinda']} imÃ³veis na 'berlinda'.")

    print("="*50)
    print("ðŸ› FIM DO MODO DEPURAÃ‡ÃƒO")
    print("="*50 + "\n")
# ==============================================================================
# FIM DO BLOCO DE DEPURAÃ‡ÃƒO
# ==============================================================================

# %%
# %%
# Calcular mÃ©tricas para a Berlinda
print("\nðŸŽ¯ Calculando mÃ©tricas especÃ­ficas para Berlinda...")

# Filtrar apenas Berlinda
df_berlinda = df_final[df_final["grupo_criticidade"] == "berlinda"].copy()

# --- FunÃ§Ãµes Auxiliares ---
def calcular_dias_disponiveis(df, data_ref):
    """Calcula os dias disponÃ­veis com base na data de referÃªncia."""
    ultimo_dia_mes = data_ref + pd.offsets.MonthEnd(0)
    if data_ref.date() == ultimo_dia_mes.date():
        return 0
    dias_restantes = (ultimo_dia_mes - data_ref).days
    return df['ocupacao_ainda_disponivel'].clip(upper=dias_restantes).fillna(0).astype(int)

def calcular_potenciais(df):
    """Calcula os potenciais mÃ¡ximo e realista."""
    df["potencial_max"] = (
        df["faturamento_mes"] + (df["dias_disponiveis"] * df["media_preco_disponivel"])
    )
    df["potencial_realista"] = (
        df["faturamento_mes"] + 
        (df["to_listings"] * df["dias_disponiveis"] * df["media_preco_disponivel"])
    )

def classificar_status(row):
    """Classifica o status operacional de um imÃ³vel."""
    if row["atingimento_meta"] >= 1.0:
        return "ðŸŸ¡ Acima com risco" if row["dias_disponiveis"] > 0 else "ðŸŸ¡ Acima sem aÃ§Ã£o"
    else:
        if row["dias_disponiveis"] == 0:
            return "ðŸ”´ Abaixo inviÃ¡vel"
        return "ðŸŸ¢ Abaixo viÃ¡vel" if row["potencial_realista"] >= row["meta"] else "ðŸŸ  Abaixo precisa esforÃ§o"

# --- LÃ³gica Principal ---
if len(df_berlinda) > 0:
    print(f"ðŸ› DEBUG: Colunas encontradas no df_berlinda: {df_berlinda.columns.tolist()}")
    
    # VerificaÃ§Ã£o crÃ­tica da coluna de data
    if 'data_da_execucao' not in df_berlinda.columns or df_berlinda['data_da_execucao'].isnull().all():
        print("âš ï¸ A coluna 'data_da_execucao' nÃ£o foi encontrada ou estÃ¡ toda nula. Pulando o cÃ¡lculo de mÃ©tricas.")
        df_berlinda = pd.DataFrame()
    else:
        df_berlinda.dropna(subset=['data_da_execucao'], inplace=True)
        if df_berlinda.empty:
            print("âš ï¸ ApÃ³s limpar nulos, o df_berlinda ficou vazio. Pulando o cÃ¡lculo.")
        else:
            # PreparaÃ§Ã£o inicial
            data_ref = pd.to_datetime(df_berlinda['data_da_execucao'].iloc[0])
            df_berlinda['dias_disponiveis'] = calcular_dias_disponiveis(df_berlinda, data_ref)
            df_berlinda["dias_necessarios"] = df_berlinda.apply(
                lambda row: np.ceil(row["falta_meta"] / row["media_preco_disponivel"]) 
                if row["media_preco_disponivel"] > 0 else 0, axis=1
            )
            calcular_potenciais(df_berlinda)

            # Separar para cÃ¡lculo de score
            df_abaixo = df_berlinda[df_berlinda["atingimento_meta"] < 1.0].copy()
            df_acima = df_berlinda[df_berlinda["atingimento_meta"] >= 1.0].copy()

            # --- CÃ¡lculo de Score para "Abaixo da Meta" ---
            if not df_abaixo.empty:
                df_abaixo["score_bruto"] = (
                    (df_abaixo["falta_meta"] / df_abaixo["meta"]) *
                    (1 / df_abaixo["dias_disponiveis"].replace(0, 1)) *
                    (df_abaixo["potencial_max"] - df_abaixo["faturamento_mes"]) *
                    (1 / df_abaixo["dias_necessarios"].replace(0, 1))
                )
                df_abaixo["score_normalizado"] = df_abaixo["score_bruto"].rank(pct=True) * 100

            # --- CÃ¡lculo de Score para "Acima da Meta" (Risco) ---
            if not df_acima.empty:
                df_acima["score_risco_bruto"] = df_acima["dias_disponiveis"] * (1 / (df_acima["atingimento_meta"] - 0.99))
                df_acima["score_normalizado"] = df_acima["score_risco_bruto"].rank(pct=True) * 100

            # --- Aplicar ClassificaÃ§Ãµes ---
            def classificar_prioridade_abaixo(score):
                if score >= 80: return "CrÃ­tico"
                elif score >= 50: return "Alta"
                elif score >= 20: return "MÃ©dia"
                else: return "Baixa"

            def classificar_prioridade_acima(score):
                if score >= 80: return "Risco Alto"
                elif score >= 50: return "Risco MÃ©dio"
                elif score >= 20: return "Risco Baixo"
                else: return "Sem Risco"
                
            if not df_abaixo.empty:
                df_abaixo["faixa_prioridade"] = df_abaixo["score_normalizado"].apply(classificar_prioridade_abaixo)
                df_abaixo["status_operacional"] = df_abaixo.apply(classificar_status, axis=1)
            
            if not df_acima.empty:
                df_acima["faixa_prioridade"] = df_acima["score_normalizado"].apply(classificar_prioridade_acima)
                df_acima["status_operacional"] = df_acima.apply(classificar_status, axis=1)

            # --- Recombinar e Finalizar ---
            df_berlinda = pd.concat([df_abaixo, df_acima], ignore_index=True)
            print(f"âœ… MÃ©tricas da Berlinda calculadas para {len(df_berlinda)} imÃ³veis.")

else:
    print("âš ï¸ Nenhum imÃ³vel encontrado na Berlinda neste snapshot.")

# %%
# Salvar resultados
print("\nðŸ’¾ Salvando arquivos processados...")

# ==============================================================================
# 1. NOVO: Extrair a data de execuÃ§Ã£o para o nome do arquivo
# ==============================================================================
# Verificamos se o DataFrame nÃ£o estÃ¡ vazio antes de tentar acessar a coluna
if not df_final.empty:
    # Pega a data da primeira linha, converte para o formato datetime e depois para string 'YYYY-MM-DD'
    run_date_str = pd.to_datetime(df_final['data_da_execucao'].iloc[0]).strftime('%Y-%m-%d')
else:
    # Fallback: caso o DataFrame esteja vazio, usa a data atual
    run_date_str = pd.to_datetime('today').strftime('%Y-%m-%d')
print("âš ï¸ DataFrame final vazio. Usando data atual para o nome do arquivo.")

# O nome do arquivo agora inclui a data da execuÃ§Ã£o
output_final = os.path.join(PROCESSED_DIR, f"meta_analysis_final_enriched_{run_date_str}.csv")
df_final.to_csv(output_final, index=False, encoding='utf-8')
print(f"âœ… Salvo: {output_final}")

# Salvar DataFrame da Berlinda
if len(df_berlinda) > 0:
    # O nome do arquivo tambÃ©m inclui a data da execuÃ§Ã£o
    output_berlinda = os.path.join(PROCESSED_DIR, f"berlinda_prepared_{run_date_str}.csv")
    df_berlinda.to_csv(output_berlinda, index=False, encoding='utf-8')
    print(f"âœ… Salvo: {output_berlinda}")

# %%
# %%
# Exibir estatÃ­sticas finais
print("\nðŸ“Š EstatÃ­sticas finais:")
print(f"ðŸ“ˆ Total de imÃ³veis analisados: {len(df_final)}")
print(f"ðŸŽ¯ ImÃ³veis na Berlinda: {len(df_berlinda)}")

# <<< NOVA VERIFICAÃ‡ÃƒO: Mostrar estatÃ­sticas da Berlinda apenas se ela nÃ£o estiver vazia
if not df_berlinda.empty and 'status_operacional' in df_berlinda.columns:
    print("\nðŸ“‹ DistribuiÃ§Ã£o de status na Berlinda:")
    print(df_berlinda["status_operacional"].value_counts())
    
    print("\nðŸ“‹ DistribuiÃ§Ã£o de prioridade na Berlinda:")
    print(df_berlinda["faixa_prioridade"].value_counts())
else:
    print("\nðŸ“‹ NÃ£o hÃ¡ dados da Berlinda para exibir as estatÃ­sticas.")

print("\nðŸ“‰ Valores nulos no DataFrame final:")
print(df_final.isnull().sum())

print("\nðŸŽ‰ Processamento concluÃ­do com sucesso!")
